{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dOaoFoIv-F2"
   },
   "source": [
    "# **ArtLine**\n",
    "**Create** **amazing** **lineart** **portraits** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JN8RJVoKv8Lt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.vision.gan import *\n",
    "from torchvision.models import vgg16_bn\n",
    "from fastai.utils.mem import *\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYpkQrvncqB1"
   },
   "source": [
    "##**Edge Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CqG1XipRciT5"
   },
   "outputs": [],
   "source": [
    "def _gradient_img(img):\n",
    "    img = img.squeeze(0)\n",
    "    ten=torch.unbind(img)\n",
    "    x=ten[0].unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    a=np.array([[1, 0, -1],[2,0,-2],[1,0,-1]])\n",
    "    conv1=nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    conv1.weight=nn.Parameter(torch.from_numpy(a).float().unsqueeze(0).unsqueeze(0))\n",
    "    G_x=conv1(Variable(x)).data.view(1,x.shape[2],x.shape[3])\n",
    "\n",
    "    b=np.array([[1, 2, 1],[0,0,0],[-1,-2,-1]])\n",
    "    conv2=nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    conv2.weight=nn.Parameter(torch.from_numpy(b).float().unsqueeze(0).unsqueeze(0))\n",
    "    G_y=conv2(Variable(x)).data.view(1,x.shape[2],x.shape[3])\n",
    "\n",
    "    G=torch.sqrt(torch.pow(G_x,2)+ torch.pow(G_y,2))\n",
    "    return G\n",
    "\n",
    "gradient = TfmPixel(_gradient_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlGPepVInaQo"
   },
   "source": [
    "**PATH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PwBuA4R0m2zf"
   },
   "outputs": [],
   "source": [
    "path = Path('./content/gdrive/My Drive/Apdrawing')\n",
    "\n",
    "# Blended Facial Features\n",
    "\n",
    "path_hr = Path('./content/gdrive/My Drive/Apdrawing/draw tiny')\n",
    "path_lr = Path('./content/gdrive/My Drive/Apdrawing/Tiny Real')\n",
    "\n",
    "# Portrait Pair\n",
    "\n",
    "path_hr3 = Path('./content/gdrive/My Drive/Apdrawing/drawing')\n",
    "path_lr3= Path('./content/gdrive/My Drive/Apdrawing/Real')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0wVDG4onf7G"
   },
   "source": [
    "**Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0zieELiLnSbr"
   },
   "outputs": [],
   "source": [
    "arch = models.resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvQrKkYkshF7"
   },
   "source": [
    "### **Facial Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5S0vl06RnTMv"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\\content\\gdrive\\My Drive\\Apdrawing\\Tiny Real is not a valid directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cff5cd498336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageImageList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_lr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_by_rand_pct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PytorchEnv\\lib\\site-packages\\fastai\\vision\\data.py\u001b[0m in \u001b[0;36mfrom_folder\u001b[1;34m(cls, path, extensions, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;34m\"Get the list of files in `path` that have an image suffix. `recurse` determines if we search subfolders.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mextensions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_extensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PytorchEnv\\lib\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36mfrom_folder\u001b[1;34m(cls, path, extensions, recurse, exclude, include, processor, presort, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m         `recurse` determines if we search subfolders.\"\"\"\n\u001b[0;32m    128\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{path} is not a valid directory.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         return cls(get_files(path, extensions, recurse=recurse, exclude=exclude, include=include, presort=presort), \n\u001b[0;32m    131\u001b[0m                    path=path, processor=processor, **kwargs)\n",
      "\u001b[1;31mAssertionError\u001b[0m: \\content\\gdrive\\My Drive\\Apdrawing\\Tiny Real is not a valid directory."
     ]
    }
   ],
   "source": [
    "src = ImageImageList.from_folder(path_lr).split_by_rand_pct(0.3, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tJphvDRnkO8"
   },
   "outputs": [],
   "source": [
    "def get_data(bs,size):\n",
    "    data = (src.label_from_func(lambda x: path_hr/x.name)\n",
    "           .transform(get_transforms(xtra_tfms=[gradient()]), size=size, tfm_y=True)\n",
    "           .databunch(bs=bs,num_workers = 0).normalize(imagenet_stats, do_y=True))\n",
    "\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yetcm3CHn0Dq"
   },
   "source": [
    "**64px**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-Xoit4Mnvb-"
   },
   "outputs": [],
   "source": [
    "bs,size=20,64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fqJZQfanmmV"
   },
   "outputs": [],
   "source": [
    "data = get_data(bs,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a-wREZlnpD9"
   },
   "outputs": [],
   "source": [
    "data.show_batch(ds_type=DatasetType.Valid, rows=2, figsize=(9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLOmfrvWn4Uy"
   },
   "outputs": [],
   "source": [
    "t = data.valid_ds[0][1].data\n",
    "t = torch.stack([t,t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "it5H7CoPn4q_"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzkaAicvn7Gi"
   },
   "outputs": [],
   "source": [
    "gram_matrix(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkORIHa4n-Fh"
   },
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYQnhpgxoAEF"
   },
   "outputs": [],
   "source": [
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CnEahFKoCPB"
   },
   "outputs": [],
   "source": [
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [vgg_m[i] for i in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwtR5uSAoFgR"
   },
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rwt3AAMDoGKv"
   },
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YtjntlCoIgo"
   },
   "outputs": [],
   "source": [
    "wd = 1e-3\n",
    "y_range = (-3.,3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faBs7PvAoQcY"
   },
   "outputs": [],
   "source": [
    "def create_gen_learner():\n",
    "    return unet_learner(data, arch, wd=wd, blur=True,norm_type=NormType.Spectral,self_attention=True, y_range=(-3.0, 3.0),\n",
    "                        loss_func=feat_loss, callback_fns=LossMetrics)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UIo4hEwoS4o"
   },
   "outputs": [],
   "source": [
    "learn_gen = create_gen_learner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_WqNg6NoU5I"
   },
   "outputs": [],
   "source": [
    "learn_gen.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4OK0nMYoYRI"
   },
   "outputs": [],
   "source": [
    "lr = 1-01\n",
    "epoch = 5\n",
    "def do_fit(save_name, lrs=slice(lr), pct_start=0.9):\n",
    "    learn_gen.fit_one_cycle(epoch, lrs, pct_start=pct_start,)\n",
    "    learn_gen.save(save_name)\n",
    "    learn_gen.show_results(rows=1, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4EcXwfXoc2Q"
   },
   "outputs": [],
   "source": [
    "do_fit('da', slice(lr))\n",
    "#lr*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzoUTyG7pm-d"
   },
   "outputs": [],
   "source": [
    "learn_gen.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kIQ5qGYppbS"
   },
   "outputs": [],
   "source": [
    "learn_gen.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB2tZvVzpt-s"
   },
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "do_fit('db', slice(1E-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtEI1s2BqFz2"
   },
   "source": [
    "**128px**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqKWCsBgp236"
   },
   "outputs": [],
   "source": [
    "data = get_data(8,128)\n",
    "learn_gen.data = data\n",
    "learn_gen.freeze()\n",
    "gc.collect()\n",
    "learn_gen.load('db');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlFdd8pOp9N1"
   },
   "outputs": [],
   "source": [
    "epoch =5\n",
    "lr = 1E-03\n",
    "do_fit('db2',slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDFMDymEqDDm"
   },
   "outputs": [],
   "source": [
    "learn_gen.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55vcLnbrqK2p"
   },
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "do_fit('db3', slice(1e-02,1e-5), pct_start=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMSbEIC8qYv1"
   },
   "source": [
    "**192px**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLmzmoJ7qTJy"
   },
   "outputs": [],
   "source": [
    "data = get_data(5,192)\n",
    "learn_gen.data = data\n",
    "learn_gen.freeze()\n",
    "gc.collect()\n",
    "learn_gen.load('db3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdxT7G9Wqdud"
   },
   "outputs": [],
   "source": [
    "epoch =5\n",
    "lr = 1E-06\n",
    "do_fit('db4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gABZH1FwqjeG"
   },
   "outputs": [],
   "source": [
    "learn_gen.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqWh1dLTql8z"
   },
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "do_fit('db5', slice(1e-06,1e-4), pct_start=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_YqXNzjq8m3"
   },
   "source": [
    "# **Portraits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD6ognJgqqd6"
   },
   "outputs": [],
   "source": [
    "src = ImageImageList.from_folder(path_lr3).split_by_rand_pct(0.2, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFws14t6rA6y"
   },
   "outputs": [],
   "source": [
    "def get_data(bs,size):\n",
    "    data = (src.label_from_func(lambda x: path_hr3/x.name)\n",
    "           .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n",
    "           .databunch(bs=bs,num_workers = 0).normalize(imagenet_stats, do_y=True))\n",
    "\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45kYzAwvrL9T"
   },
   "source": [
    "**128px**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ish7mEzdrEDa"
   },
   "outputs": [],
   "source": [
    "data = get_data(8,128)\n",
    "learn_gen.data = data\n",
    "learn_gen.freeze()\n",
    "gc.collect()\n",
    "learn_gen.load('db5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdUSomYArTNH"
   },
   "outputs": [],
   "source": [
    "data.show_batch(ds_type=DatasetType.Valid, rows=2, figsize=(9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAlhXL46re94"
   },
   "outputs": [],
   "source": [
    "learn_gen.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADT1-uoyrhbA"
   },
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "lr = 1e-03\n",
    "do_fit('db6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whapmkF0rmHu"
   },
   "outputs": [],
   "source": [
    "learn_gen.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdO4W55TrqQE"
   },
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "do_fit('db7', slice(6.31E-07,1e-5), pct_start=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMHRoP1Vr5zA"
   },
   "source": [
    "**192px**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_YCV5tYryyV"
   },
   "outputs": [],
   "source": [
    "data = get_data(4,192)\n",
    "learn_gen.data = data\n",
    "learn_gen.freeze()\n",
    "gc.collect()\n",
    "learn_gen.load('db7');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0buABN-r82o"
   },
   "outputs": [],
   "source": [
    "learn_gen.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crNFdzojr_vS"
   },
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "lr = 4.37E-05\n",
    "do_fit('db8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRJ_954VsDW7"
   },
   "outputs": [],
   "source": [
    "learn_gen.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mr8mvuhVsGk2"
   },
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "do_fit('db9', slice(1.00E-05,1e-3), pct_start=0.3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
